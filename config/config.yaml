defaults:
  - dataset: cub_200_312
  - model: protocbm

universal:
  monitor: val_c2y_acc_cls
  mode: max
  data_path: ./data
  log_path: ./logs/${model.type}-${dataset.name}
  x_mean: [0.485, 0.456, 0.406]
  x_std: [0.229, 0.224, 0.225]
  early_stop_patience: 10
  lr_patience: 5

optimiser:
  type: adam
  lr: 0.00001
  weight_decay: 0.0001

lr_scheduler:
  type: plateau
  monitor: ${universal.monitor}
  mode: ${universal.mode}
  patience: ${universal.lr_patience}
  factor: 0.1
  min_lr: 1e-08
  verbose: True
  threshold: 0.01
  cooldown: 0

trainer:
  precision: 32
  max_epochs: 100
  profiler: null

log_level: INFO

evaluation:
  cas:
    step: 50

# Loggers
wandb:
  _target_: lightning.pytorch.loggers.WandbLogger
  name: ${model.type}-${dataset.name}
  entity: linus-cambridge
  project: "Part3-ProtoCBM"
  tags: []
  settings:
    _target_: wandb.Settings
    start_method: thread

tensorboard:
  dir: ${universal.log_path}/tensorboard/
  name: protocbm

# Callbacks
callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: ${universal.monitor}
    mode: ${universal.mode}
    patience: ${universal.early_stop_patience}
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.model_checkpoint.ModelCheckpoint
    monitor: ${universal.monitor}
    mode: ${universal.mode}
    save_top_k: 1
    every_n_epochs: null
    save_on_train_epoch_end: null
    dirpath: ${universal.log_path}/ckpt
  model_summary:
    _target_: lightning.pytorch.callbacks.RichModelSummary
    max_depth: 1
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar